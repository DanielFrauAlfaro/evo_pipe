###### Pinza 4F:
    - Inclusión en la simulación: se debe poner a 0.0 la inercia de todos los eslabones de la pinza en las definición
    de los parámetros de configuración para que aparezca correctamente en Gazebo, ya que en RVIZ se ve bien en
    principio

    - Se pueden controlar los 4 dedos por separado, ya que el control se hace en articulares, tanto en real como en simulación

    - Topic de planificación: /move_group/motion_plan_request --> moveit_msgs/MotionPlanRequest
    - Topic de ejecución: /execute_trajectory/goal --> moveit_msgs/ExecuteTrajectoryActionGoal


/allegroHand_0/joint_cmd      --> Mensaje tipo sensor_msgs/JointState		--> Se puede indicar el movimiento de cada dedo con el mensaje (aunque sea el mismo que el JointStates)
/allegroHand_0/lib_cmd        --> Mensaje tipo std_msgs/String 			--> Tipo de movimiento ("home", "ready", ...)
/allegroHand_0/joint_states   --> Mensaje tipo sensor_msgs/JointState		--> Estado de las articulaciones
	

##### Pinza 3F:
    - Ancho dos dedos: 12.5 cm
    - Ancho palma: 10.5 cm
    - Entre dedos: 11.1 cm
    - MAX: 15.5 cm
    - Entre dedos enfrentados: 9.25 cm


##### Objetos elegidos (28): --> Están todos en la carpeta /evo_pipe/ycb como SDF
    - Gelatin box 
    - Mustard bottle
    - Sugar box
    - Bleach cleanser
    - Tomato soup can
    - Chocolate pudding box
    - Pear
    - Plum
    - Coffe can (Master Chef Can)
    - Tuna can
    - Windex Bottle (bleach cleanser)
    - Chips can
    - Foam brick
    - Power drill
    - Stacking blocks (big one)
    - Softball
    - Enamel-coated metal bowl
    - Timer
    - Spring Clamps (big)
    - 9 hole peg
    - a Colored wood blocks (la caja entera)
    - Pitcher
    - Cracker Box
    - Banana
    - Mug
    - Potted Meat Can
    - Orange
    - Flat Screwdriver


    Para poder incluirlos en la simulación no se ha utilizado el formato URDF sino que se ha usado el formato SDF 
de Gazebo. Para ello se ha modificado el código original en los siguientes puntos:
    - DockerFile:
        - l. 177: ++ RUN echo "export GAZEBO_MODEL_PATH=$GAZEBO_MODEL_PATH:/daniel/Desktop/evo_pipe/ycb" >> ~/.bashrc
        Se ha añadido otra asignación del parámetro del sistema 'GAZEBO_MODEL_PATH' para que Gazebo seleccione como
    directorio para obtener sus modelos la carpeta '/ycb' donde están los modelos SDF de los objetos

    - catkin_ws/src/experimental_settings/launch/simulation.launch:
        - l. 25: <arg name="objects_dir" value="/daniel/Desktop/evo_pipe/ROS_URDF_objects/" /> --> <arg name="objects_dir" value="/daniel/Desktop/evo_pipe/ycb/" />
        Se cambia el directorio desde el que se obtienen los modelos, del de los URDF al de los SDF en '/ycb'

    - catkin_ws/src/experimental_settings/src/object.cpp: 
        - l. 50: chosenObjects.push_back(objects[random]+"/model.urdf"); --> chosenObjects.push_back(objects[random]+"/model.sdf");
        Se cambia el archivo de configuracion de los modelos al ser estos SDF.

    - catkin_ws/src/experimental_settings/src/load_delete_objects.cpp:
        - l. 93: ++ spawn.request.model_name="object";
        Se añade un nombre a la petición del servicio de importación del objeto
        - l. 98: std::string topicGazebo = "/gazebo/spawn_urdf_model"; --> std::string topicGazebo = "/gazebo/spawn_sdf_model";
        Se cambia el servicio que importa los modelos, ya que en vez de ser URDF son SDF, por lo que se requiere el 
        servicio con el mismo nombre


############# PREGUNTAS #################
    - Como serían los parámetros de Geograsp para la pinza de 4 dedos, sobretodo como funciona el parámetro de separación
    - Comentar que la pinza de 4 dedos, al igual que con la de 3, es muy difícil meterla dentro de Moveit. La de tres dedos
    no debería hacer falta, ya que es adaptable, pero la de 4 es mas probable. Se podría hacer publicando en los topics de
    control o hacer cadenas cinemáticas para cada dedo y planificar con ellos.



########### TAREAS ######################

TERMINADO
    - Mirar segmentación de objetos planos  -->  Segmenta bien pero aun así solo saca un plano, lo que dificulta
el cálculo de puntos de agarre
    - Cambiar el cierre de la pinza, debe ser cada dedo independiente: cuando se detecte un contacto, incrementar un 
poco el cierre y pararse (con dos flags alomejor). Cuando se tenga contacto en los tres, detener el cierre 
--> Terminado a priori. Está con dos flags para cada dedo; cuando se activa uno, se hace un incremento más y cuando
se activa el siguiente (que va una iteración por detrás del otro) deja de mover el dedo. También, si no se detecta nada
resetea los dos flags
    - Testear si el topic de cmd de la allegro tiene en cuenta la posición de los valores publicando valores de home -->
Funciona si están en orden del 0 al 15, tal cual se publica el topic /allegro0/joint_states de la allegro
    - Comprobar como funciona el /joint_states de moveit para ver si se puede engañar --> se puede engañar a moveit. En
el move_group.launch he hehco el remap de los topics, aunque está con parámetros, de manera que si se lanza ese launch
se ejecuta normal, mientras se puede modificar desde línea de comandos u otro launch. 
    IMPORTANTE: Hay veces que al realizar una trayectoria falla por inconsistencias en el goal (fallo al llegar al GOAL),
por lo que para moveit todavía no ha llegado a esa posición. La siguiente planificación la tomará desde el punto inicial
de la anterior trayectoria, no desde el final / actual. Para solucionar el problema se puede hacer una planificación y 
ejecución de una trayectoria con otro grupo de movimiento. También se podría aumentar la tolerancia de Moveit.
    - Comprobar las masas de los objetos en simulación --> Se ha guardado una copia de las originales en caso de 
    necesitar un back-up. Pesar algunos objetos como el Windex_Bottle, puede no coincidir
    - Reducir el rango de aparición de los objetos, es demasiado amplio y está demasiado escorado hacia la derecha, por
eso muchas de las trayectorias falla; los puntos están bien generalmente, pero el objeto está en una posición 
inconveniente --> Hecho, aunque a veces se queda el objeto alejado de la zona, por el punto de referencia del objeto
supongo

    - Hacer la configuración de Geograsp con la pinza de 4 dedos --> Está hecha
    IMPORTANTE: preguntar a ver si está bien, están estimadas a ojo con el pulgar abierto y cerrado

    - La razón por la que en un inicio las físicas de Gazebo fallaban es por los controladores del robot, no era por la
fricción (puede que estén demasiado altas incluso) ni por las colisiones (que si que las detecta). Esto se debe a que 
las físicas de Gazebo no funcionan bien con controladores en posición, que era como se habían configurado los 
controladores desde un inicio. Por ello se tienen que utilizar controladores de esfuerzo en las articulaciones de los 
robots. 
También se ha anulado los valores inerciales del modelo de la mesa por si diera problemas con el rozamiento e impidiera
a los objetos moverse sobre ella cuando los empuja al agarrarlos (esto parece no ser significativo) 


EN PROCESO
    - Meter en la carpeta del dataset la taza y la potted_meat_can del YCB, que no las vi y están en la caja de los 
    objetos que no son de YCB del laboratorio --> Pregunar si alguien las va a usar, porque están ahí
    - IMPORTANTE: se tiene que cambiar el topic de states del UR5e real, a ver donde hacer el remapeo --> se puede 
    comprobar haciendo grupos en un launch en simulación; si se lanza el bringup con un grupo y el moveit sin, alomejor
    no se ven entre ellos y se puede usar el puente

    - Comprobar de estimar el vector perpendicular a la recta que minimice el ángulo con la vertical del eje Z --> Hay
solución por optimización (Wolfram Alpha) pero no la puedo sacar analíticamente. De momento está que si se tienen dos
puntos similares se coge la vertical del eje Z como perpendicular al plano
    IMPORTANTE: la optimización se hace usando el método de Lagrange, añadiendo una ecuación auxiliar al cálculo
    ESTO NO SALE NO SE PORQUE, el problema tiene que estar mal planeado teóricamente pero no se por dondeç
    IMPORTANTE: dejo esto aparcado de momento. Es mucho lío el cambio de sistemas de referencia y orientaciones para que 
salga correctamente

    - Hacer un servicio auxiliar por si falla el planificador de Moveit. Lo que debería hacer es si se planifica una
trayectoria inválida, se active un servicio que reciba el punto de destino y lleve al robot allí directamente mediante
los topics articulares del robot. Para ello antes se debe calcular la cinemática inversa del robot en el punto de 
destino y aplicarla directamente. Una vez acabe la trayectoria, se indica el resultado al programa principal para seguir
con el funcionamiento normal --> Se podría usar Python con la Robotic Toolbox o mirar otra solución en C++.
    IMPORTANTE: está hecho 
    

SIN EMPEZAR

    - Sacar paquete de Moveit de la Allegro solo
    

###### ERRORES --> Siempre da error en la "joint_0" o "joint_1"
    - Error de planificación Moveit: [ERROR] [1691563141.203459658]: 
Invalid Trajectory: start point deviates from current robot state more than 0.01
joint 'joint_0': expected: 0.0933329, current: 0.0550587

###### Posición random_valid:
  - joint_0
  - joint_1
  - joint_2
  - joint_3
  - joint_4
  - joint_5
  - joint_6
  - joint_7
  - joint_8
  - joint_9
  - joint_10
  - joint_11
  - joint_12
  - joint_13
  - joint_14
  - joint_15
position: [-0.09464827826864083, 0.8350591778610523, 0.7890181857074536, 0.7150823886708259, -0.05413490951110592, 0.36794109894322113, 1.226975475852992, 1.0281541430911414, 0.3993582859121047, -0.10876406951319414, 1.1157451208438416, -0.023902065015476193, 1.1421239783931725, 0.6524758975189661, 0.9201927361148228, 0.8503960606504295]
velocity: [-0.008938840238798464, 0.003325726167712293, 0.0035951679482925524, -0.00817849959148776, 0.01634635386823065, -0.0021008476675325534, 0.003930375721802611, 0.011505324213372779, 0.00770633466722688, 0.001936511963086346, -0.022864192200872088, -0.00635048599862382, 0.01521741380676608, -0.017639792880576533, 0.0027646597903756044, 0.011584980875279238]
effort: [-0.02557162960424807, -0.057606131348584215, -0.06186359804221549, -0.07580544983982494, -0.03965863641358786, -0.025284355802451794, -0.01126091494790644, 0.02519957022319347, 0.010622535456581182, 0.045262103905533355, 0.019336746913010353, -0.03589716939105627, 0.12661101695078966, 0.19621681249529033, 0.02254170406700629, 0.03032203371421542]


####### Pipeline de lanzamiento en real (3F) ########
    - UR5e y pinza 3F encendido                                                     - Terminal 1
    - RealSense encendida conectada con el ordenador                                - Terminal 2
    - UR5e conectado al ordenador via Ethernet con el control external_control      - Terminal 3
    - Pinza 3F conectada via Ethernet mediante el launch del fabricante             - Terminal 4
-- Comprobar que se pueden ver los topics
    
-- En cuanto a la visualización del proyecto                                        - Terminal 5 (todo lo de abajo)
    - RVIZ del proyecto, se debe de poder ver:                                   (configurar un entorno de RVIZ con esto)
        - El planificador de Moveit
        - La imagen tridimensional capturada por la RealSense
        - La imagen bidimensional capturada por la RealSense
        - Escenario de manipulación

-- En cuanto a los nodos:
    - El nodo coordinador central adaptado a la ejecución en real (sin llamadas al spawner de objetos de la simulación)
    - El nodo de Geograsp
    - El nodo de Moveit adaptado al entorno real (move_group del Moveit real, publicación en topics de la pinza real, ...)
    - El nodo que envíe los mensajes a la pinza de tres dedos
IMPORTANTE: este último nodo se puede integrar dentro del nodo de Moveit, pero alomejor queda un poco farragoso






- Fallos del GeoGrasp:
    - Parece que no hay problema en la traducción de los puntos, ya que los puntos que devuelve el nodo de geoGrasp del
paquete "experiment_settings" son los mismos que los representados en RVIZ. Esto se ha podido observar mostrando las 
nubes de puntos finales con los puntos de agarre en el nodo y luego viendo los puntos en RVIZ en el programa.
    Se están haciendo algunos "rosbags" que almacenen la información de los experimentos fallidos junto con algunas 
capturas explicativas de los problemas.

    - En la prueba de "naranja_bien?_2" se han visto los puntos que devuelve el algoritmo y no se cumple que la distancia
(al menos entre dos de ellos) se de 0.036 metros. Los puntos son:

        - 
        x: -0.036385491490364075
        y: 0.010523765347898006
        z: 0.3767339885234833
        - 
        x: -0.07914240658283234
        y: 0.05286387354135513
        z: 0.367044597864151
        - 
        x: -0.08975385874509811
        y: 0.041447531431913376
        z: 0.3676515519618988

    Y las distancias serían:
        - Puntos 1 y 2: 0.123
        - Puntos 1 y 3: 0.13
        - Puntos 2 y 3: 0.17

    Ninguna es igual que la distancia especificada como parámetro en el fichero .launch.


    Al parecer lo que estaba ocurriendo era que a la hora de pasar a enteros los parámetros de la apertura de la pinza 
se obviaba que podía existir una distancia negativa según el sistema de referencia, por lo que el rango era entre 0 y 
36. Esto provocaba que se pudieran dar coincidencias en los puntos de agarre

    Aun asi se siguen dando algunos agarres en los que si que se producen puntos coincidentes. También hay problemas con
los objetos que son percibidos como un plano por la cámara RGBD, indicando los puntos de agarre sobre el objeto, lo que
resulta imposible. Este último hecho es esperado debido a que la nube de puntos representa parcialmente la forma del
objeto.

    El problema se ha solucionado al parecer. Los valores de apertura debían ser decimales, es decir, estar en metros, no en
milímetros, como estaba en un inicio. Esto hace que los rangos se calculen correctamente y no de espacio a valores no válidos
(como era el caso de los puntos coincidentes). 
    La pinza de tres dedos funciona como una pinza de dos dedos normal, ya que los dedos conjuntos no permiten ningún tipo de 
maniobrabilidad, simplemente cierran. Por ello, se ha decidido cerrar hasta que se detecte contacto, con lo que se evitan posibles
imprecisiones a la hora del cierre debido al movimiento del objeto por un contacto temprano de cada uno de los dedos (la pinza real
incorpora esta funcionalidad también). Aún así, puede suceder que uno de los dedos no haga contacto con el objeto durante el cierre,
debido a que el objeto es demasiado pequeño usualmente. 
    En los objetos que tienen una superficie plana no funciona demasiado bien, ya que los puntos siguen estando encima del objeto,
lo que imposibilita llevar el robot a esos puntos.


    Para el caso real se tiene que cambiar el método por el que se calcula el punto de agarre, ya que está para que la obtenga 
del sistema de referencia del objeto directamente, lo que no resulta adecuado. Por lo tanto se tiene que usar el punto medio que
devuelve Moveit!. De esta manera, el robot irá al punto medio. 

    IMPORTANTE: preguntar a Ignacio si sabe desde donde se toma el sistema de referencia en el caso del Moveit! real. En simulación es
el link del mundo. En real entiendo que es el base_link, pero por asegurar  

    DEDUCCIÓN: En real se tiene todo respecto al "base_link", o al menos eso es lo que se usa en el Moveit! que se lanza con el real. Así, entiendo
que todas las transformaciones que se hacen en simulación respecto al "world" se deberían hacer en real respecto al "base_link".




################### COSAS QUE HACER #########
    - Presentación para el Robot2023 - Plantilla Gmail de Ignacio. 
        - Estructura:
            - Introducción: establecer el problema, el espacio de trabajo, zonas, herramientas, ...
            - System Description: esquema de control (imágenes), cálculo de impedancias, interfaz gráfica...
            - Experiments: imágenes del artículo original
                - Grasping Results: imágenes del agarre real y en simulación
                - Data acquisition: gráficas de los datos en simulación y real (alomejor en simulación se puede omitir)
            - Conclusions and Future Work: hablar de para que se pretenden utilizar los datos generados con la interfaz 
        

    - Artículo MDPI:
        - Leerse la plantilla por encima
        - Crear una copia para tener la plantilla a mano
        - Cómo enfocar el artículo:
            - Contribución: interfaz para generar entornos tanto de simulación en Pybullet y Gazebo, asi como conexión con entornos reales
            para la generación de trayectorias en el ámbito del aprendizaje por refuerzo (o demostración o RLfD).

            - Estructura:
                - Introducción: introducir el tema y exponer la contribución. Resumir contenido.
                - Materials and methods:
                    - Materials: exponer de que equipo se dispone y las plataformas en las que se ha llevado a cabo el desarrollo.
                    - Methods: hablar de la realimentación de fuerzas, esquema de control (cambiar la imagen), máquina de estados del control, interfaz gráfica, ...
                    Se podría hablar también de los diferentes nodos y abstracciones que se tienen en cuenta para llevar a cabo el proyecto 
                    (nodo del Phantom, controlador cartesiano, controlador articular, nodo joint_states, ...) -> posible imagen / esquema
                - Results: 
                    - Following Trajectory experiments: gráficas del seguimiento en simulación (ponerlas como si fueran las reales), tabla de los errores (si la puedo sacar), ...
                    - System Experiments: experimentos para la evaluación del sistema en su conjunto (pruebas de agarre pero con otro nombre)
                - Discussion: argumentación de porque estos resultados son adecuados para aprendizaje por refuerzo y de que el interfaz
                permite la generación de entornos con éxito.
                - Conclusions: (no creo que haga falta, en la Discussion se pone todo) repetir un poco la contribución 
                - Appendix A: se puede añadir un apéndice para mostrar el análisis de rendimiento

    
    - GeoGrasp:
        - Probar la cámara para comprobar el topic y capturar una nube de puntos. 
        - Hacer la adaptación para hacer los agarres con la pinza de 3 dedos real -> un nodo en Python que reciba la señal de moverse y que 
        al acabar mande un mensaje al nodo de moveit o simplemente esperar cierto instante o esperar una pulsación del usuario (cin)
        - Hacer las pruebas con la pinza real para comprobar el funcionamiento del topic de contacto poniendo el dedo o un objeto en medio
        - Guardar un punto de la simulación y llevar el robot real ahí, a ver si coincide 

        - Pruebas paso a paso:
            - Captura de la nube de puntos
            - Procesamiento de GeoGrasp
            - Visualización de los puntos de agarre
            - Planificación y ejecución con Moveit!
            - Agarre con la pinza de tres dedos real 


############## IMPORTANTE #################
    - En el robot real todas las transformaciones se deben realizar respecto al "base_link"
    - Según las salidas del código, la posición que calcula GeoGrasp aplicándole los giros de 45º que hizo Ignacio coincide con las coordenadas
    objetivo respecto al "base_link"
    - El "shoulder_pan_joint" tiene +90º de offset de la simulación al real (pos_sim + 90 = pos_real). Corregir esto.
    - Mirar a ver al pasarle una de las posiciones cartesianas de la simulación al robot real, va a una posición 
    correcta o se gira para el lado. De no hacerlo bien, habría que aplicar un giro de 90º en el eje Z a los puntos de 
    GeoGrasp como última transformación

    - En principio el controlador de la pinza está, junto con la conexion en el nodo de moveit. Lo unico que faltaría
    sería comprobar si se reciben los mensajes y se envían los comandos. También falta por ver los valores que envía la pinza para
    los contactos

    - Lanzar la RealSense con el fichero "_mine" que está preparado para lanzar el topic que muestra la point_cloud


    - Base sim = Base_real - 90z
    - Base_link_sim = Base_link_real + 90


    - Se ha modificado el modelo del robot con la pinza de tres dedos en simulación para que coincida con el real. Habían varios problemas asociados a este
    cambio.
        - El "objectAxis" NO es el sistema de referencia (frame) del objeto que saca Gazebo al importarlo, sino que es un sistema de referencia ficticio
        creado a partir de los puntos de agarre, por lo que es correcto en simulación y real
        - Se han cambiado todas las transformaciones respecto al "base_link" (antes estaban con el "world") para que coincidan con el robot real (en real no
        hay "world"). Por ello, se debe cambiar el origen del planificador desde el "world" (lo coge Moveit por defecto) al nuevo "base_link"
        - Al cambiar el "base_link" al del original del UR5e, se observó que no se pintaban correctamente los Markers y se intercambiaban los ejes X y Z en
        el extremo del robot, lo que provocaba que el robot se acercara al objeto de lado. Para corregir esto se rotó el sistema de orientación 90º según
        el eje Y positivo del sistema de referencia formado por los puntos de geograsp (o lo que es lo mismo: Z = X   X = -Z). También se cambió el incremento
        a la hora de pintar los markers para que coindidieran las direcciones en el sistema de coordenadas del "base_link". Finalmente, se añadió una rotación
        de 45º según el eje positivo Z (antes era negativa pero con el cambio de "world" a "base_link" se añaden 180º) para hacer coincidir el sistema de referencia
        de geoGrasp con el de Moveit


--------- DOCKER cosas ----------
Habilitar gráfica en la Docker:
    ENV NVIDIA_VISIBLE_DEVICES ${NVIDIA_VISIBLE_DEVICES:-all}
    ENV NVIDIA_DRIVER_CAPABILITIES all


--------------
Transformacion a una PCD: https://pointclouds.org/documentation/tutorials/matrix_transform.html
Tutoriales PCL: https://pcl.readthedocs.io/projects/tutorials/en/master/#basic-usage
Tutorial RANSAC: https://adioshun.gitbooks.io/pcl/content/Tutorial/SampleConsensus/how-to-use-random-sample-consensus-model.html